{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c98ff-6281-482c-9e5c-2180d9c9d34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video reconstruction overall plan\n",
    "# 1. train a generator model to reconstruct video from activations of ResNet3D\n",
    "\n",
    "# 2. train a linear fxn to map neural activity to activations\n",
    "\n",
    "# 3. use to generate videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e73f17b5-de0e-45dd-9d39-43e42c3f478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "# all parameters\n",
    "config = dict()\n",
    "config[\"modality\"] = \"video\" # or image\n",
    "\n",
    "# paths\n",
    "input_dir = f'../data/{config[\"modality\"]}/'\n",
    "stimulus_dir = f'../data/{config[\"modality\"]}/stimuli/'\n",
    "embedding_dir = f'../data/{config[\"modality\"]}/embeddings/'\n",
    "model_output_path = f'../data/{config[\"modality\"]}/model_output/results'\n",
    "\n",
    "# dataset and dataloader hyperparameters \n",
    "config[\"win_size\"] = 240\n",
    "config['pos'] = (400, 180)\n",
    "config[\"feat_ext_type\"] = 'resnet3d'\n",
    "config[\"stim_size\"] = 32 \n",
    "config[\"stim_dur_ms\"] = 200\n",
    "config[\"stim_shape\"] = (1, 3, 5, config[\"stim_size\"], config[\"stim_size\"])\n",
    "config[\"first_frame_only\"] = False\n",
    "config[\"exp_var_thresholds\"] = [0.25, 0.25, 0.25] #[0.25, 0.25, 0.25]\n",
    "config[\"batch_size\"] = 16\n",
    "\n",
    "# model hyperparameters\n",
    "config[\"layer\"] = \"layer2\"\n",
    "config[\"use_sigma\"] = True\n",
    "config[\"center_readout\"] = False\n",
    "config[\"use_pool\"] = True\n",
    "config[\"pool_size\"] = 4\n",
    "config[\"pool_stride\"] = 2\n",
    "config[\"use_pretrained\"] = True\n",
    "config[\"flatten_time\"] = True\n",
    "\n",
    "# training parameters \n",
    "config[\"lr\"] = 0.001 \n",
    "config[\"num_epochs\"] = 20\n",
    "config[\"l2_weight\"] = 0\n",
    "\n",
    "# logging\n",
    "config[\"wandb\"] = True\n",
    "\n",
    "# save model\n",
    "config[\"save\"] = True\n",
    "\n",
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# session names\n",
    "session_ids = [\"082824\", \"082924\", \"083024\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c3039ec-37cf-4a4f-861b-0dbca44bf857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.video import r3d_18\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b191babc-086a-4f41-9082-c3027651732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_ext = create_feature_extractor(r3d_18(), return_nodes={  'layer2.0.conv1.1': 'layer'}).to(device)\n",
    "for param in feat_ext.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d4f67267-e44c-4ef8-8302-4a51eb1b76d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 3, 8, 8])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_ext(torch.zeros((1,3,5,32,32), device=device))['layer'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0694c3e9-16b5-4283-aa24-1f1244cb8bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 5, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, output_channels=3, vid_size=32):\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv1 = nn.ConvTranspose3d(128, 128, 4, 2, 1, device=device)\n",
    "        self.conv2 = nn.ConvTranspose3d(128, 64, 4, 2, 1, device=device)\n",
    "        self.conv3 = nn.Conv3d(64, output_channels, 3, 1, 1, device=device)\n",
    "        self.conv4 = nn.Conv3d(output_channels, output_channels, 3, 1, 1, device=device)\n",
    "        self.conv5 = nn.Conv3d(12, 5, 3, 1, 1, device=device)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.vid_size = vid_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = x.permute(0, 2, 1, 3, 4)\n",
    "        x = (self.conv5(x)).permute(0, 2, 1, 3, 4)\n",
    "        x = self.sig(x)*4 - 2\n",
    "        return x\n",
    "\n",
    "# generator maps from torch.Size([1, 128, 3, 8, 8]) to torch.Size([1,3,5,32,32])\n",
    "g = Generator()\n",
    "print(g(torch.zeros((1,128,3,8,8), device=device)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5632f982-7fb9-4cf5-b562-39c1a556a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator \n",
    "from fix_models.datasets import get_datasets_and_loaders\n",
    "\n",
    "# get the dataloaders for videos \n",
    "ses_idx = 0\n",
    "session_id = session_ids[ses_idx]\n",
    "datasets = []\n",
    "loaders = []\n",
    "for i in range(120, 520, 20):\n",
    "    for j in range(120, 240, 20):\n",
    "        train_dataset, _, train_loader, _ = get_datasets_and_loaders(input_dir, session_id, config[\"modality\"], config[\"exp_var_thresholds\"][ses_idx], config[\"stim_dur_ms\"], config[\"stim_size\"], config[\"win_size\"], stimulus_dir, config[\"batch_size\"], config[\"first_frame_only\"], pos = (i, j), test_bs=True)\n",
    "        loaders.append(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82846ffb-15f8-429f-b021-fe1e4a9d9897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/120], Loss: 124.8757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/120], Loss: 61.7440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/120], Loss: 23.9900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/120], Loss: 20.2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/120], Loss: 17.3144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/120], Loss: 15.2031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/120], Loss: 15.4717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/120], Loss: 14.3226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/120], Loss: 13.8025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/120], Loss: 13.0804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/120], Loss: 12.2668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/120], Loss: 12.0861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/120], Loss: 12.2204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/120], Loss: 12.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/120], Loss: 11.6572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/120], Loss: 11.0764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/120], Loss: 10.7689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/120], Loss: 10.3270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/120], Loss: 11.1234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/120], Loss: 10.8014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/120], Loss: 10.3395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/120], Loss: 10.2168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/120], Loss: 9.6265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/120], Loss: 9.6440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/120], Loss: 10.2835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/120], Loss: 9.9711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/120], Loss: 9.9826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/120], Loss: 9.8356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/120], Loss: 9.1992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/120], Loss: 8.9807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/120], Loss: 9.7883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/120], Loss: 9.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/120], Loss: 9.5123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/120], Loss: 9.2246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/120], Loss: 8.9580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/120], Loss: 8.5228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/120], Loss: 9.6460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/120], Loss: 9.4986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/120], Loss: 8.9672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/120], Loss: 8.5626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/120], Loss: 8.6256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/120], Loss: 8.2485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/120], Loss: 9.0365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/120], Loss: 8.7884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/120], Loss: 8.7795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/120], Loss: 8.3995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:07<00:00, 18.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/120], Loss: 8.2795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/120], Loss: 7.9499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/120], Loss: 8.7250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/120], Loss: 8.6119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/120], Loss: 8.5587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/120], Loss: 8.1315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/120], Loss: 7.9699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/120], Loss: 7.7346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/120], Loss: 8.7149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/120], Loss: 8.5332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/120], Loss: 8.2330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/120], Loss: 8.0371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/120], Loss: 7.7519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/120], Loss: 7.6563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/120], Loss: 8.4350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/120], Loss: 8.0485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/120], Loss: 8.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/120], Loss: 7.8148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/120], Loss: 7.6561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/120], Loss: 7.5442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/120], Loss: 8.3485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/120], Loss: 7.9975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/120], Loss: 7.6934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/120], Loss: 7.6391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:07<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/120], Loss: 7.2874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/120], Loss: 7.2850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:07<00:00, 17.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/120], Loss: 7.8879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/120], Loss: 7.7394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/120], Loss: 7.5192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/120], Loss: 7.3895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/120], Loss: 7.3065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/120], Loss: 7.1048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/120], Loss: 7.7027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/120], Loss: 7.6697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/120], Loss: 7.7022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/120], Loss: 7.3015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/120], Loss: 7.1612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/120], Loss: 6.9685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/120], Loss: 7.6103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/120], Loss: 7.1986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/120], Loss: 7.2786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/120], Loss: 7.0209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/120], Loss: 6.9980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/120], Loss: 6.8611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/120], Loss: 7.8229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/120], Loss: 7.4048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/120], Loss: 7.2225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/120], Loss: 6.9729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/120], Loss: 6.8771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 18.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/120], Loss: 6.7062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/120], Loss: 7.3221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/120], Loss: 7.2344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/120], Loss: 7.1014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/120], Loss: 6.9036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [101/120], Loss: 6.7169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [102/120], Loss: 6.6135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [103/120], Loss: 7.3205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [104/120], Loss: 6.9657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 127/127 [00:06<00:00, 19.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [105/120], Loss: 6.9066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% 114/127 [00:05<00:00, 21.03it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(g.parameters(), lr=0.0002)\n",
    "\n",
    "num_epochs = len(loaders)\n",
    "for epoch, loader in enumerate(loaders):\n",
    "    losses = 0\n",
    "    for images, targets in tqdm(loader):\n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(device)\n",
    "        feats = feat_ext(images)\n",
    "        reconstructed_images = g(feats['layer'])\n",
    "        loss = criterion(reconstructed_images, images)\n",
    "        losses += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {losses:.4f}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63abc021-fca9-4d37-b339-2a90b305667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(g.state_dict(), \"./generator.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d524ce-fb8d-43f4-8b8e-ad3f8cce4cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Step 2: Define a function for visualization\n",
    "def visualize_reconstruction(generator, feat_ext, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    # Get a single test image\n",
    "    for images, _ in test_loader:\n",
    "        test_image = images[0].unsqueeze(0)  # Add batch dimension\n",
    "        break\n",
    "\n",
    "    # Pass the image through the model to get clean activations\n",
    "    with torch.no_grad():\n",
    "        acts = feat_ext(test_image.to(device))['layer']\n",
    "\n",
    "    # Generate reconstruction from clean activations\n",
    "    reconstruction = generator(acts)\n",
    "\n",
    "    # Convert images to numpy arrays for visualization\n",
    "    test_image_np = test_image[:, :, 0, :, :].squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "    reconstruction_np = clean_reconstruction[:, :, 0, :, :].squeeze(0).permute(1, 2, 0).detach().cpu().numpy()\n",
    "\n",
    "    MEAN = np.array([0.485, 0.456, 0.406])\n",
    "    STD = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "    # Clip and normalize for visualization\n",
    "    test_image_np = test_image_np * STD + mean\n",
    "    test_image_np = np.clip(test_image_np, 0, 1)\n",
    "    reconstruction_np = reconstruction_np * STD + mean\n",
    "    reconstruction_np = np.clip(reconstruction_np, 0, 1)\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(8, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(test_image_np)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(reconstruction_np)\n",
    "    plt.title(\"Reconstruction (No Noise)\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Step 3: Visualize the reconstruction\n",
    "for _ in range(10):\n",
    "  visualize_reconstruction(g, feat_ext, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa7be6e-586e-4126-a66e-a18108ec1676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet3d\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Step 1: Load and preprocess CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "train_dataset, _, train_loader, _ = get_datasets_and_loaders(input_dir, session_id, config[\"modality\"], config[\"exp_var_thresholds\"][ses_idx], config[\"stim_dur_ms\"], config[\"stim_size\"], config[\"win_size\"], stimulus_dir, config[\"batch_size\"], config[\"first_frame_only\"], pos = config['pos'], test_bs=True)\n",
    "\n",
    "# Step 2: Load pretrained ResNet18\n",
    "resnet = resnet18(pretrained=True)\n",
    "resnet.eval()  # Set to evaluation mode\n",
    "\n",
    "# Select a particular layer for activations (e.g., layer4[1].conv2)\n",
    "layer_to_hook = resnet.layer3[0].relu\n",
    "\n",
    "# Define a hook to capture activations\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "layer_to_hook.register_forward_hook(get_activation('selected_layer'))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Step 3: Define a function to create noisy samples from Poisson processes\n",
    "def poisson_sample(activations):\n",
    "    rate_params = activations.view(activations.size(0), -1).cpu().numpy()  # Flatten the activations\n",
    "\n",
    "    noisy_samples = np.random.poisson(rate_params).astype(np.float32)\n",
    "    return torch.tensor(noisy_samples)\n",
    "\n",
    "# Step 4: Create custom dataset of image and samples from Poisson processes\n",
    "class ImagePoissonDataset(Dataset):\n",
    "    def __init__(self, data_loader, model, layer_name):\n",
    "        self.data_loader = data_loader\n",
    "        self.model = model.to(device)\n",
    "        self.layer_name = layer_name\n",
    "        self.images = []\n",
    "        self.samples = []\n",
    "        self.create_dataset()\n",
    "\n",
    "    def create_dataset(self):\n",
    "        for images, _ in tqdm(self.data_loader):\n",
    "            if len(self.images) <= len(train_dataset)*1/2:\n",
    "              with torch.no_grad():\n",
    "                  _ = self.model(images.to(device))\n",
    "                  activations = activation[self.layer_name]\n",
    "                  self.images.extend(images)\n",
    "                  self.samples.extend(poisson_sample(activations))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx], self.images[idx]\n",
    "\n",
    "poisson_dataset = ImagePoissonDataset(train_loader, resnet, 'selected_layer')\n",
    "poisson_loader = DataLoader(poisson_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4db25e96-0285-41b1-b318-f573e124bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import torch.nn.functional as F\n",
    "from fix_models.feature_extractors import get_video_feature_extractor, VideoFeatureExtractor\n",
    "from fix_models.readouts import PoissonGaussianReadout, PoissonLinearReadout\n",
    "\n",
    "# neural activity embedding model \n",
    "class NeuralEmbedder(nn.Module):\n",
    "    def __init__(self, num_neurons, num_layers = 3, hidden_size = 16, embed_size = 16, device=torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        self.num_neurons = num_neurons\n",
    "        self.embed_size = num_neurons #embed_size #um_neurons #embed_size\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_neurons, hidden_size, device=device)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size, device=device)\n",
    "        self.linear3 = nn.Linear(hidden_size, embed_size, device=device)\n",
    "\n",
    "        self.linear = nn.Linear(num_neurons, embed_size, device=device)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.linear1(x))\n",
    "        x = x + self.act(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        x = (self.linear(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "# video embedding model\n",
    "class VideoEmbedder(nn.Module):\n",
    "    def __init__(self, modality, layer, stim_shape, train_dataset, feat_ext_type = 'resnet3d', use_pool = False, pool_size = 2, pool_stride = 2, use_pretrained = True, freeze_weights=True, flatten_time = False, device=torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "        num_neurons = len(train_dataset[0][1])\n",
    "\n",
    "        feat_ext = get_video_feature_extractor(layer=layer, mod_type=feat_ext_type, device=device, use_pretrained=use_pretrained, freeze_weights=freeze_weights)\n",
    "        feat_ext = VideoFeatureExtractor(feat_ext, stim_shape, device=device)\n",
    "        \n",
    "        readout_input = feat_ext(train_dataset[0][0].unsqueeze(0).to(device))\n",
    "        num_input  = readout_input.shape[1] * readout_input.shape[2]\n",
    "        \n",
    "        feat_to_embed = FeatToEmbed(use_pool = use_pool, pool_size = pool_size, pool_stride= pool_stride, device=device)\n",
    "        #neu_embed = NeuralEmbedder(num_neurons, device=device) #num_input, device=device)\n",
    "        neu_embed = nn.Linear(num_input, num_neurons, device=device)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            feat_ext,\n",
    "            feat_to_embed,\n",
    "            neu_embed\n",
    "        )\n",
    "            \n",
    "        print(f\"readout input shape: {num_input}\")\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        return self.act(self.model(x)) + 1\n",
    "\n",
    "class FeatToEmbed(nn.Module):\n",
    "    def __init__(self, use_pool = False, pool_size = 2, pool_stride = 2, device=torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.use_pool = use_pool\n",
    "        \n",
    "        # pooling size\n",
    "        self.pool = nn.AvgPool2d(pool_size, stride=pool_stride, padding=int(pool_size/2), count_include_pad=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        n_batch, n_channel, n_time, width, height = x.shape\n",
    "        x = x.view(n_batch, n_channel * n_time, width, height)\n",
    "        \n",
    "        if self.use_pool:\n",
    "            x = self.pool(x)\n",
    "\n",
    "        grid = torch.zeros((x.shape[0], 1, 1, 2), device=self.device)\n",
    "        grid = torch.clamp(grid, min=-1, max=1) # clamp to ensure within feature map\n",
    "\n",
    "        x = torch.squeeze(torch.squeeze(F.grid_sample(x, grid, align_corners=False), -1), -1)        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dce4ad2-aeb4-4bb9-9d05-fcbcc946ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "from torch.nn import PoissonNLLLoss\n",
    "from fix_models.metrics import get_decoder_accuracy\n",
    "\n",
    "from fix_models.datasets import get_datasets_and_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "102dbe0d-1a68-4f2d-94f5-cf11c86eb13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "# all parameters\n",
    "config = dict()\n",
    "config[\"modality\"] = \"video\" # or image\n",
    "\n",
    "# paths\n",
    "input_dir = f'../data/{config[\"modality\"]}/'\n",
    "stimulus_dir = f'../data/{config[\"modality\"]}/stimuli/'\n",
    "embedding_dir = f'../data/{config[\"modality\"]}/embeddings/'\n",
    "model_output_path = f'../data/{config[\"modality\"]}/model_output/results'\n",
    "\n",
    "# dataset and dataloader hyperparameters \n",
    "config[\"win_size\"] = 240\n",
    "config['pos'] = (400, 180)\n",
    "config[\"feat_ext_type\"] = 'resnet3d'\n",
    "config[\"stim_size\"] = 32 \n",
    "config[\"stim_dur_ms\"] = 200\n",
    "config[\"stim_shape\"] = (1, 3, 5, config[\"stim_size\"], config[\"stim_size\"])\n",
    "config[\"first_frame_only\"] = False\n",
    "config[\"exp_var_thresholds\"] = [0.25, 0.25, 0.25] #[0.25, 0.25, 0.25]\n",
    "config[\"batch_size\"] = 16\n",
    "\n",
    "# model hyperparameters\n",
    "config[\"layer\"] = \"layer2\"\n",
    "config[\"use_sigma\"] = True\n",
    "config[\"center_readout\"] = False\n",
    "config[\"use_pool\"] = True\n",
    "config[\"pool_size\"] = 4\n",
    "config[\"pool_stride\"] = 2\n",
    "config[\"use_pretrained\"] = True\n",
    "config[\"flatten_time\"] = True\n",
    "\n",
    "# training parameters \n",
    "config[\"lr\"] = 0.001 \n",
    "config[\"num_epochs\"] = 20\n",
    "config[\"l2_weight\"] = 0\n",
    "\n",
    "# logging\n",
    "config[\"wandb\"] = True\n",
    "\n",
    "# save model\n",
    "config[\"save\"] = True\n",
    "\n",
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# session names\n",
    "session_ids = [\"082824\", \"082924\", \"083024\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb49cf5f-09b8-41de-88c5-f3a359a826b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# note - this loss function was written by chatgpt with some edits\n",
    "def triplet_loss(vid_embed, neu_embed, alpha):\n",
    "    \"\"\"\n",
    "    Compute the triplet loss for given video and neural embeddings.\n",
    "    \n",
    "    Args:\n",
    "        vid_embed (torch.Tensor): Tensor of shape (batch_size, embed_size) for video embeddings.\n",
    "        neu_embed (torch.Tensor): Tensor of shape (batch_size, embed_size) for neural embeddings.\n",
    "        alpha (float): Margin value for the triplet loss.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Scalar loss value.\n",
    "    \"\"\"\n",
    "    # Compute pairwise distances\n",
    "    #vid_embed = F.normalize(vid_embed, p=2, dim=1)\n",
    "    #neu_embed = F.normalize(neu_embed, p=2, dim=1)\n",
    "\n",
    "    vid_embed_norm = vid_embed.unsqueeze(1)  # Shape: (batch_size, 1, embed_size)\n",
    "    neu_embed_norm = neu_embed.unsqueeze(0)  # Shape: (1, batch_size, embed_size)\n",
    "    pairwise_dist = torch.sum((vid_embed_norm - neu_embed_norm) ** 2, dim=2)  # Shape: (batch_size, batch_size)\n",
    "\n",
    "    # Find the \"challenging negatives\"\n",
    "    # Set diagonal to a large value to exclude positives\n",
    "    pairwise_dist.fill_diagonal_(float('inf'))  \n",
    "    challenging_negatives_idx = torch.argmin(pairwise_dist, dim=1)  # Shape: (batch_size,)\n",
    "    shuffled_neu_embed = neu_embed[challenging_negatives_idx]  # Shape: (batch_size, embed_size)\n",
    "\n",
    "    # Compute distances for positives and negatives\n",
    "    pos_dist = torch.sum((vid_embed - neu_embed) ** 2, dim=1)  # Shape: (batch_size,)\n",
    "    neg_dist = torch.sum((vid_embed - shuffled_neu_embed) ** 2, dim=1)  # Shape: (batch_size,)\n",
    "\n",
    "    # Compute triplet loss\n",
    "    loss = F.relu(pos_dist - neg_dist + alpha)  # Shape: (batch_size,)\n",
    "    return loss.mean()  # Scalar loss value\n",
    "\n",
    "\n",
    "def train_model(full_vid, full_neu, model_name):\n",
    "    # corr avgs\n",
    "    corr_avgs = []\n",
    "\n",
    "    config['model_name'] = model_name\n",
    "\n",
    "    print(config['l2_weight'])\n",
    "    \n",
    "    for ses_idx, session_id in enumerate(session_ids):\n",
    "        # set sess_corr_avg\n",
    "        sess_corr_avg = -1\n",
    "        sess_corrs = []\n",
    "\n",
    "        # set session index \n",
    "        config[\"session_id\"] = session_id\n",
    "\n",
    "        # setup logging\n",
    "        if config[\"wandb\"]:\n",
    "            wandb.init(\n",
    "                project=f'{config[\"modality\"]}-cs230-decode',\n",
    "                config=config,\n",
    "            )\n",
    "            wandb.define_metric(\"decode_acc\", summary=\"max\")\n",
    "            wandb.define_metric(\"test_loss\", summary=\"min\")\n",
    "\n",
    "        # load datasets and loaders \n",
    "        train_dataset, test_dataset, train_loader, test_loader = get_datasets_and_loaders(input_dir, session_id, config[\"modality\"], config[\"exp_var_thresholds\"][ses_idx], config[\"stim_dur_ms\"], config[\"stim_size\"], config[\"win_size\"], stimulus_dir, config[\"batch_size\"], config[\"first_frame_only\"], pos = config['pos'], test_bs=True)\n",
    "        _, _, _, test_loader_single = get_datasets_and_loaders(input_dir, session_id, config[\"modality\"], config[\"exp_var_thresholds\"][ses_idx], config[\"stim_dur_ms\"], config[\"stim_size\"], config[\"win_size\"], stimulus_dir, config[\"batch_size\"], config[\"first_frame_only\"], pos = config['pos'], test_bs=False)\n",
    "\n",
    "        full_vid_embedder = full_vid(train_dataset)\n",
    "        full_neu_embedder = full_neu(len(train_dataset[0][1]))\n",
    "\n",
    "        # set which parameters to use regularization with and which not to\n",
    "        params_with_l2 = []\n",
    "        params_without_l2 = []\n",
    "        for name, param in full_vid_embedder.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                params_without_l2.append(param)\n",
    "            else:\n",
    "                params_with_l2.append(param)\n",
    "\n",
    "        # setup Adam optimizer\n",
    "        vid_optimizer = torch.optim.Adam([\n",
    "            {'params': params_with_l2, 'weight_decay': config['l2_weight']},  # Apply L2 regularization (weight decay)\n",
    "            {'params': params_without_l2, 'weight_decay': 0.0}  # No L2 regularization\n",
    "        ], lr=config[\"lr\"], weight_decay=config['l2_weight'])\n",
    "        \n",
    "        params_with_l2 = []\n",
    "        params_without_l2 = []\n",
    "        for name, param in full_neu_embedder.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                params_without_l2.append(param)\n",
    "            else:\n",
    "                params_with_l2.append(param)\n",
    "\n",
    "        neu_optimizer = torch.optim.Adam([\n",
    "            {'params': params_with_l2, 'weight_decay': config['l2_weight']},  # Apply L2 regularization (weight decay)\n",
    "            {'params': params_without_l2, 'weight_decay': 0.0}  # No L2 regularization\n",
    "        ], lr=config[\"lr\"], weight_decay=config['l2_weight'])\n",
    "    \n",
    "        # using triplet loss   \n",
    "        alpha = 0.1\n",
    "        loss_func = PoissonNLLLoss(log_input=False, full=True)\n",
    "\n",
    "        for epochs in range(config[\"num_epochs\"]):\n",
    "            epoch_loss = 0\n",
    "            for i, (stimulus, targets) in enumerate(train_loader): \n",
    "                vids = stimulus.to(device)\n",
    "                neus = targets.to(device)\n",
    "\n",
    "                vid_optimizer.zero_grad()\n",
    "                neu_optimizer.zero_grad()\n",
    "                \n",
    "                vid_embed = full_vid_embedder(vids)\n",
    "                neu_embed = full_neu_embedder(neus)\n",
    "\n",
    "                #loss = triplet_loss(vid_embed, neu_embed, alpha) #+ triplet_loss(neu_embed, vid_embed, alpha)\n",
    "                loss = loss_func(vid_embed, neu_embed)\n",
    "                loss.backward()\n",
    "\n",
    "                vid_optimizer.step()\n",
    "                neu_optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "    \n",
    "            # printing corr to avg and loss metrics \n",
    "            with torch.no_grad():\n",
    "                decode_acc = get_decoder_accuracy(full_vid_embedder, full_neu_embedder, test_loader_single, modality=config[\"modality\"], device=device)\n",
    "                test_loss = 0\n",
    "                for i, (stimulus, targets) in enumerate(test_loader):\n",
    "                    vids = stimulus.to(device)\n",
    "                    neus = targets.to(device)\n",
    "                    vid_embed = full_vid_embedder(vids)\n",
    "                    neu_embed = full_neu_embedder(neus)\n",
    "                    loss = triplet_loss(vid_embed, neu_embed, alpha) #+ triplet_loss(neu_embed, vid_embed, alpha)\n",
    "                    test_loss += loss.item()\n",
    "                    \n",
    "            if config[\"wandb\"]:\n",
    "                wandb.log({\"decode_acc\": np.nanmean(decode_acc), \"train_loss\": epoch_loss / len(train_loader), \"test_loss\": test_loss / len(test_loader)})\n",
    "            \n",
    "            if np.nanmean(decode_acc) > sess_corr_avg:\n",
    "                sess_corr_avg = np.nanmean(decode_acc)\n",
    "                sess_corrs = decode_acc\n",
    "                \n",
    "            print('  epoch {} loss: {} decode acc: {}'.format(epochs + 1, epoch_loss / len(train_dataset), np.nanmean(decode_acc)))\n",
    "            #print(f' num. neurons : {len(decode_acc)}')\n",
    "            \n",
    "        #if config[\"save\"]:\n",
    "        #    torch.save(full_model.state_dict(), f\"{model_output_path}_{session_id}.pickle\")\n",
    "            \n",
    "        corr_avgs.append(sess_corrs)\n",
    "        \n",
    "        if config[\"wandb\"]:\n",
    "            wandb.finish()\n",
    "    \n",
    "    if config[\"wandb\"]:\n",
    "        wandb.init(\n",
    "            project=f'{config[\"modality\"]}-cs230-decode',\n",
    "            config=config,\n",
    "        )\n",
    "        for corr in corr_avgs:\n",
    "            wandb.log({\"decode_accs\": corr})\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "376fdba1-b893-4528-b745-f6acfc60c177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33met22\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/src/models/cs230/wandb/run-20241130_224340-5tl5854s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/et22/video-cs230-decode/runs/5tl5854s' target=\"_blank\">noble-glade-33</a></strong> to <a href='https://wandb.ai/et22/video-cs230-decode' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/et22/video-cs230-decode' target=\"_blank\">https://wandb.ai/et22/video-cs230-decode</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/et22/video-cs230-decode/runs/5tl5854s' target=\"_blank\">https://wandb.ai/et22/video-cs230-decode/runs/5tl5854s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readout input shape: 384\n",
      "  epoch 1 loss: 0.12235652758751386 decode acc: 0.4\n",
      "  epoch 2 loss: 0.11666988143214473 decode acc: 0.425\n",
      "  epoch 3 loss: 0.11594631830851237 decode acc: 0.525\n",
      "  epoch 4 loss: 0.11545191882569113 decode acc: 0.625\n",
      "  epoch 5 loss: 0.11518091713940656 decode acc: 0.65\n",
      "  epoch 6 loss: 0.11494378407796224 decode acc: 0.675\n",
      "  epoch 7 loss: 0.11477671752741307 decode acc: 0.7\n",
      "  epoch 8 loss: 0.11464894265304378 decode acc: 0.675\n",
      "  epoch 9 loss: 0.114555534845517 decode acc: 0.675\n",
      "  epoch 10 loss: 0.11443922148810493 decode acc: 0.675\n",
      "  epoch 11 loss: 0.11430847003136152 decode acc: 0.7\n",
      "  epoch 12 loss: 0.11425545280362352 decode acc: 0.725\n",
      "  epoch 13 loss: 0.11421989635184959 decode acc: 0.725\n",
      "  epoch 14 loss: 0.11407451235217812 decode acc: 0.725\n",
      "  epoch 15 loss: 0.1139945031389778 decode acc: 0.775\n",
      "  epoch 16 loss: 0.11393759845215597 decode acc: 0.725\n",
      "  epoch 17 loss: 0.11387442035439574 decode acc: 0.775\n",
      "  epoch 18 loss: 0.11379451810577769 decode acc: 0.75\n",
      "  epoch 19 loss: 0.11377660945609763 decode acc: 0.725\n",
      "  epoch 20 loss: 0.11379066902914164 decode acc: 0.75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>decode_acc</td><td></td></tr><tr><td>test_loss</td><td></td></tr><tr><td>train_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>1.81438</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">noble-glade-33</strong> at: <a href='https://wandb.ai/et22/video-cs230-decode/runs/5tl5854s' target=\"_blank\">https://wandb.ai/et22/video-cs230-decode/runs/5tl5854s</a><br/> View project at: <a href='https://wandb.ai/et22/video-cs230-decode' target=\"_blank\">https://wandb.ai/et22/video-cs230-decode</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241130_224340-5tl5854s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/src/models/cs230/wandb/run-20241130_224740-vtqgk9ej</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/et22/video-cs230-decode/runs/vtqgk9ej' target=\"_blank\">young-durian-34</a></strong> to <a href='https://wandb.ai/et22/video-cs230-decode' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/et22/video-cs230-decode' target=\"_blank\">https://wandb.ai/et22/video-cs230-decode</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/et22/video-cs230-decode/runs/vtqgk9ej' target=\"_blank\">https://wandb.ai/et22/video-cs230-decode/runs/vtqgk9ej</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readout input shape: 384\n",
      "  epoch 1 loss: 0.11582509591317301 decode acc: 0.425\n",
      "  epoch 2 loss: 0.11172449326640024 decode acc: 0.475\n",
      "  epoch 3 loss: 0.11096722617823417 decode acc: 0.5\n",
      "  epoch 4 loss: 0.11060457728920182 decode acc: 0.625\n",
      "  epoch 5 loss: 0.11036484790722113 decode acc: 0.675\n",
      "  epoch 6 loss: 0.11010989206623657 decode acc: 0.7\n",
      "  epoch 7 loss: 0.10996435649732021 decode acc: 0.725\n",
      "  epoch 8 loss: 0.10985431664901255 decode acc: 0.725\n",
      "  epoch 9 loss: 0.10970041146453138 decode acc: 0.75\n",
      "  epoch 10 loss: 0.10965823971164164 decode acc: 0.7\n",
      "  epoch 11 loss: 0.10951418021586554 decode acc: 0.7\n",
      "  epoch 12 loss: 0.10951287640326934 decode acc: 0.65\n",
      "  epoch 13 loss: 0.10947642725799721 decode acc: 0.725\n",
      "  epoch 14 loss: 0.10932655565401646 decode acc: 0.725\n",
      "  epoch 15 loss: 0.10929544646078379 decode acc: 0.75\n",
      "  epoch 16 loss: 0.1092259022577895 decode acc: 0.725\n",
      "  epoch 17 loss: 0.10922847686637759 decode acc: 0.675\n",
      "  epoch 18 loss: 0.1091297878020721 decode acc: 0.675\n",
      "  epoch 19 loss: 0.10916048113588263 decode acc: 0.675\n",
      "  epoch 20 loss: 0.10906772145426086 decode acc: 0.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>decode_acc</td><td></td></tr><tr><td>test_loss</td><td></td></tr><tr><td>train_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>1.73599</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">young-durian-34</strong> at: <a href='https://wandb.ai/et22/video-cs230-decode/runs/vtqgk9ej' target=\"_blank\">https://wandb.ai/et22/video-cs230-decode/runs/vtqgk9ej</a><br/> View project at: <a href='https://wandb.ai/et22/video-cs230-decode' target=\"_blank\">https://wandb.ai/et22/video-cs230-decode</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241130_224740-vtqgk9ej/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/src/models/cs230/wandb/run-20241130_225136-dcszrgxa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/et22/video-cs230-decode/runs/dcszrgxa' target=\"_blank\">celestial-armadillo-35</a></strong> to <a href='https://wandb.ai/et22/video-cs230-decode' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/et22/video-cs230-decode' target=\"_blank\">https://wandb.ai/et22/video-cs230-decode</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/et22/video-cs230-decode/runs/dcszrgxa' target=\"_blank\">https://wandb.ai/et22/video-cs230-decode/runs/dcszrgxa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readout input shape: 384\n",
      "  epoch 1 loss: 0.13410460462375562 decode acc: 0.225\n",
      "  epoch 2 loss: 0.12483198423774874 decode acc: 0.325\n",
      "  epoch 3 loss: 0.12399968047425508 decode acc: 0.45\n",
      "  epoch 4 loss: 0.12350221407974095 decode acc: 0.5\n",
      "  epoch 5 loss: 0.12310866862138818 decode acc: 0.5\n",
      "  epoch 6 loss: 0.12284618314643189 decode acc: 0.575\n",
      "  epoch 7 loss: 0.12260553814609598 decode acc: 0.625\n",
      "  epoch 8 loss: 0.12241629599044042 decode acc: 0.625\n",
      "  epoch 9 loss: 0.12229219753338155 decode acc: 0.65\n",
      "  epoch 10 loss: 0.12215043415299748 decode acc: 0.65\n",
      "  epoch 11 loss: 0.12201044838726785 decode acc: 0.7\n",
      "  epoch 12 loss: 0.12192451414431527 decode acc: 0.675\n",
      "  epoch 13 loss: 0.12184440264579144 decode acc: 0.675\n",
      "  epoch 14 loss: 0.12175369236251371 decode acc: 0.675\n",
      "  epoch 15 loss: 0.12169908646894115 decode acc: 0.65\n",
      "  epoch 16 loss: 0.1216364912787897 decode acc: 0.65\n",
      "  epoch 17 loss: 0.12159374374780596 decode acc: 0.65\n",
      "  epoch 18 loss: 0.12153085048154275 decode acc: 0.65\n",
      "  epoch 19 loss: 0.12146421217135656 decode acc: 0.625\n",
      "  epoch 20 loss: 0.12144065500892362 decode acc: 0.65\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>decode_acc</td><td></td></tr><tr><td>test_loss</td><td></td></tr><tr><td>train_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>1.94133</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">celestial-armadillo-35</strong> at: <a href='https://wandb.ai/et22/video-cs230-decode/runs/dcszrgxa' target=\"_blank\">https://wandb.ai/et22/video-cs230-decode/runs/dcszrgxa</a><br/> View project at: <a href='https://wandb.ai/et22/video-cs230-decode' target=\"_blank\">https://wandb.ai/et22/video-cs230-decode</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241130_225136-dcszrgxa/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/src/models/cs230/wandb/run-20241130_225619-aprok9u4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/et22/video-cs230-decode/runs/aprok9u4' target=\"_blank\">mild-thunder-36</a></strong> to <a href='https://wandb.ai/et22/video-cs230-decode' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/et22/video-cs230-decode' target=\"_blank\">https://wandb.ai/et22/video-cs230-decode</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/et22/video-cs230-decode/runs/aprok9u4' target=\"_blank\">https://wandb.ai/et22/video-cs230-decode/runs/aprok9u4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>decode_accs</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>decode_accs</td><td>0.7</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mild-thunder-36</strong> at: <a href='https://wandb.ai/et22/video-cs230-decode/runs/aprok9u4' target=\"_blank\">https://wandb.ai/et22/video-cs230-decode/runs/aprok9u4</a><br/> View project at: <a href='https://wandb.ai/et22/video-cs230-decode' target=\"_blank\">https://wandb.ai/et22/video-cs230-decode</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241130_225619-aprok9u4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_vid_fcn = lambda train_dataset: VideoEmbedder(feat_ext_type = 'resnet3d', freeze_weights=True, use_pretrained = True, modality=config[\"modality\"], layer=config[\"layer\"], stim_shape=config[\"stim_shape\"], train_dataset=train_dataset, use_pool = config['use_pool'], pool_size = config['pool_size'], pool_stride = config[\"pool_stride\"], device=device)\n",
    "full_neu_fcn = lambda num_neurons: NeuralEmbedder(num_neurons, device=device)\n",
    "\n",
    "train_model(full_vid_fcn, full_neu_fcn, \"frozen pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f21d4ed-dfa4-4d24-94ca-1a496c57f9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d93d932-2c5d-430d-8648-7e19f80790ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4db25e96-0285-41b1-b318-f573e124bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import torch.nn.functional as F\n",
    "from fix_models.feature_extractors import get_video_feature_extractor, VideoFeatureExtractor\n",
    "from fix_models.readouts import PoissonGaussianReadout, PoissonLinearReadout\n",
    "\n",
    "# neural activity embedding model \n",
    "class NeuralEmbedder(nn.Module):\n",
    "    def __init__(self, num_neurons, num_layers = 3, hidden_size = 16, embed_size = 8, device=torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        self.num_neurons = num_neurons\n",
    "        self.embed_size = num_neurons #embed_size\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_neurons, hidden_size, device=device)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size, device=device)\n",
    "        self.linear3 = nn.Linear(hidden_size, embed_size, device=device)\n",
    "\n",
    "        self.linear = nn.Linear(num_neurons, num_neurons, device=device)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.act(self.linear1(x))\n",
    "        # x = x + self.act(self.linear2(x))\n",
    "        # x = self.linear3(x)\n",
    "        x = x + self.act(self.linear(x))\n",
    "        return x\n",
    "\n",
    "# video embedding model\n",
    "class VideoEmbedder(nn.Module):\n",
    "    def __init__(self, modality, layer, stim_shape, train_dataset, feat_ext_type = 'resnet3d', use_pool = False, pool_size = 2, pool_stride = 2, use_pretrained = True, freeze_weights=True, flatten_time = False, device=torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "        num_neurons = len(train_dataset[0][1])\n",
    "\n",
    "        feat_ext = get_video_feature_extractor(layer=layer, mod_type=feat_ext_type, device=device, use_pretrained=use_pretrained, freeze_weights=freeze_weights)\n",
    "        feat_ext = VideoFeatureExtractor(feat_ext, stim_shape, device=device)\n",
    "        \n",
    "        readout_input = feat_ext(train_dataset[0][0].unsqueeze(0).to(device))\n",
    "        num_input  = readout_input.shape[1] * readout_input.shape[2]\n",
    "        \n",
    "        feat_to_embed = FeatToEmbed(use_pool = use_pool, pool_size = pool_size, pool_stride= pool_stride, device=device)\n",
    "        #neu_embed = NeuralEmbedder(num_neurons, device=device) #num_input, device=device)\n",
    "        neu_embed = nn.Linear(num_input, num_neurons, device=device)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            feat_ext,\n",
    "            feat_to_embed,\n",
    "            neu_embed\n",
    "        )\n",
    "            \n",
    "        print(f\"readout input shape: {num_input}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class FeatToEmbed(nn.Module):\n",
    "    def __init__(self, use_pool = False, pool_size = 2, pool_stride = 2, device=torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.use_pool = use_pool\n",
    "        \n",
    "        # pooling size\n",
    "        self.pool = nn.AvgPool2d(pool_size, stride=pool_stride, padding=int(pool_size/2), count_include_pad=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        n_batch, n_channel, n_time, width, height = x.shape\n",
    "        x = x.view(n_batch, n_channel * n_time, width, height)\n",
    "        \n",
    "        if self.use_pool:\n",
    "            x = self.pool(x)\n",
    "\n",
    "        grid = torch.zeros((x.shape[0], 1, 1, 2), device=self.device)\n",
    "        grid = torch.clamp(grid, min=-1, max=1) # clamp to ensure within feature map\n",
    "\n",
    "        x = torch.squeeze(torch.squeeze(F.grid_sample(x, grid, align_corners=False), -1), -1)        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dce4ad2-aeb4-4bb9-9d05-fcbcc946ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "from torch.nn import PoissonNLLLoss\n",
    "from fix_models.metrics import get_decoder_accuracy\n",
    "\n",
    "from fix_models.datasets import get_datasets_and_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "102dbe0d-1a68-4f2d-94f5-cf11c86eb13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "# all parameters\n",
    "config = dict()\n",
    "config[\"modality\"] = \"video\" # or image\n",
    "\n",
    "# paths\n",
    "input_dir = f'../data/{config[\"modality\"]}/'\n",
    "stimulus_dir = f'../data/{config[\"modality\"]}/stimuli/'\n",
    "embedding_dir = f'../data/{config[\"modality\"]}/embeddings/'\n",
    "model_output_path = f'../data/{config[\"modality\"]}/model_output/results'\n",
    "\n",
    "# dataset and dataloader hyperparameters \n",
    "config[\"win_size\"] = 240\n",
    "config['pos'] = (400, 180)\n",
    "config[\"feat_ext_type\"] = 'resnet3d'\n",
    "config[\"stim_size\"] = 32 \n",
    "config[\"stim_dur_ms\"] = 200\n",
    "config[\"stim_shape\"] = (1, 3, 5, config[\"stim_size\"], config[\"stim_size\"])\n",
    "config[\"first_frame_only\"] = False\n",
    "config[\"exp_var_thresholds\"] = [0.25, 0.25, 0.25]\n",
    "config[\"batch_size\"] = 16\n",
    "\n",
    "# model hyperparameters\n",
    "config[\"layer\"] = \"layer2\"\n",
    "config[\"use_sigma\"] = True\n",
    "config[\"center_readout\"] = False\n",
    "config[\"use_pool\"] = True\n",
    "config[\"pool_size\"] = 4\n",
    "config[\"pool_stride\"] = 2\n",
    "config[\"use_pretrained\"] = True\n",
    "config[\"flatten_time\"] = True\n",
    "\n",
    "# training parameters \n",
    "config[\"lr\"] = 0.001 \n",
    "config[\"num_epochs\"] = 20\n",
    "config[\"l2_weight\"] = 0\n",
    "\n",
    "# logging\n",
    "config[\"wandb\"] = False\n",
    "\n",
    "# save model\n",
    "config[\"save\"] = True\n",
    "\n",
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# session names\n",
    "session_ids = [\"082824\", \"082924\", \"083024\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb49cf5f-09b8-41de-88c5-f3a359a826b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# note - this loss function was written by chatgpt with some edits\n",
    "def triplet_loss(vid_embed, neu_embed, alpha):\n",
    "    \"\"\"\n",
    "    Compute the triplet loss for given video and neural embeddings.\n",
    "    \n",
    "    Args:\n",
    "        vid_embed (torch.Tensor): Tensor of shape (batch_size, embed_size) for video embeddings.\n",
    "        neu_embed (torch.Tensor): Tensor of shape (batch_size, embed_size) for neural embeddings.\n",
    "        alpha (float): Margin value for the triplet loss.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Scalar loss value.\n",
    "    \"\"\"\n",
    "    # Compute pairwise distances\n",
    "    #vid_embed = F.normalize(vid_embed, p=2, dim=1)\n",
    "    #neu_embed = F.normalize(neu_embed, p=2, dim=1)\n",
    "\n",
    "    vid_embed_norm = vid_embed.unsqueeze(1)  # Shape: (batch_size, 1, embed_size)\n",
    "    neu_embed_norm = neu_embed.unsqueeze(0)  # Shape: (1, batch_size, embed_size)\n",
    "    pairwise_dist = torch.sum((vid_embed_norm - neu_embed_norm) ** 2, dim=2)  # Shape: (batch_size, batch_size)\n",
    "\n",
    "    # Find the \"challenging negatives\"\n",
    "    # Set diagonal to a large value to exclude positives\n",
    "    pairwise_dist.fill_diagonal_(float('inf'))  \n",
    "    challenging_negatives_idx = torch.argmin(pairwise_dist, dim=1)  # Shape: (batch_size,)\n",
    "    shuffled_neu_embed = neu_embed[challenging_negatives_idx]  # Shape: (batch_size, embed_size)\n",
    "\n",
    "    # Compute distances for positives and negatives\n",
    "    pos_dist = torch.sum((vid_embed - neu_embed) ** 2, dim=1)  # Shape: (batch_size,)\n",
    "    neg_dist = torch.sum((vid_embed - shuffled_neu_embed) ** 2, dim=1)  # Shape: (batch_size,)\n",
    "\n",
    "    # Compute triplet loss\n",
    "    loss = F.relu(pos_dist - neg_dist + alpha)  # Shape: (batch_size,)\n",
    "    return loss.mean()  # Scalar loss value\n",
    "\n",
    "\n",
    "def train_model(full_vid, full_neu, model_name):\n",
    "    # corr avgs\n",
    "    corr_avgs = []\n",
    "\n",
    "    config['model_name'] = model_name\n",
    "\n",
    "    print(config['l2_weight'])\n",
    "    \n",
    "    for ses_idx, session_id in enumerate(session_ids):\n",
    "        # set sess_corr_avg\n",
    "        sess_corr_avg = -1\n",
    "        sess_corrs = []\n",
    "\n",
    "        # set session index \n",
    "        config[\"session_id\"] = session_id\n",
    "\n",
    "        # setup logging\n",
    "        if config[\"wandb\"]:\n",
    "            wandb.init(\n",
    "                project=f'{config[\"modality\"]}-cs230-decode',\n",
    "                config=config,\n",
    "            )\n",
    "            wandb.define_metric(\"decode_acc\", summary=\"max\")\n",
    "            wandb.define_metric(\"test_loss\", summary=\"min\")\n",
    "\n",
    "        # load datasets and loaders \n",
    "        train_dataset, test_dataset, train_loader, test_loader = get_datasets_and_loaders(input_dir, session_id, config[\"modality\"], config[\"exp_var_thresholds\"][ses_idx], config[\"stim_dur_ms\"], config[\"stim_size\"], config[\"win_size\"], stimulus_dir, config[\"batch_size\"], config[\"first_frame_only\"], pos = config['pos'], test_bs=True)\n",
    "        _, _, _, test_loader_single = get_datasets_and_loaders(input_dir, session_id, config[\"modality\"], config[\"exp_var_thresholds\"][ses_idx], config[\"stim_dur_ms\"], config[\"stim_size\"], config[\"win_size\"], stimulus_dir, config[\"batch_size\"], config[\"first_frame_only\"], pos = config['pos'], test_bs=False)\n",
    "\n",
    "        full_vid_embedder = full_vid(train_dataset)\n",
    "        full_neu_embedder = full_neu(len(train_dataset[0][1]))\n",
    "\n",
    "        # set which parameters to use regularization with and which not to\n",
    "        params_with_l2 = []\n",
    "        params_without_l2 = []\n",
    "        for name, param in full_vid_embedder.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                params_without_l2.append(param)\n",
    "            else:\n",
    "                params_with_l2.append(param)\n",
    "\n",
    "        # setup Adam optimizer\n",
    "        vid_optimizer = torch.optim.Adam([\n",
    "            {'params': params_with_l2, 'weight_decay': config['l2_weight']},  # Apply L2 regularization (weight decay)\n",
    "            {'params': params_without_l2, 'weight_decay': 0.0}  # No L2 regularization\n",
    "        ], lr=config[\"lr\"], weight_decay=config['l2_weight'])\n",
    "        \n",
    "        params_with_l2 = []\n",
    "        params_without_l2 = []\n",
    "        for name, param in full_neu_embedder.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                params_without_l2.append(param)\n",
    "            else:\n",
    "                params_with_l2.append(param)\n",
    "\n",
    "        neu_optimizer = torch.optim.Adam([\n",
    "            {'params': params_with_l2, 'weight_decay': config['l2_weight']},  # Apply L2 regularization (weight decay)\n",
    "            {'params': params_without_l2, 'weight_decay': 0.0}  # No L2 regularization\n",
    "        ], lr=config[\"lr\"], weight_decay=config['l2_weight'])\n",
    "    \n",
    "        # using triplet loss   \n",
    "        alpha = 0.1\n",
    "        \n",
    "        for epochs in range(config[\"num_epochs\"]):\n",
    "            epoch_loss = 0\n",
    "            for i, (stimulus, targets) in enumerate(train_loader): \n",
    "                vids = stimulus.to(device)\n",
    "                neus = targets.to(device)\n",
    "\n",
    "                vid_optimizer.zero_grad()\n",
    "                neu_optimizer.zero_grad()\n",
    "                \n",
    "                vid_embed = full_vid_embedder(vids)\n",
    "                neu_embed = full_neu_embedder(neus)\n",
    "\n",
    "                loss = triplet_loss(vid_embed, neu_embed, alpha) #+ triplet_loss(neu_embed, vid_embed, alpha)\n",
    "                loss.backward()\n",
    "                vid_optimizer.step()\n",
    "                neu_optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "    \n",
    "            # printing corr to avg and loss metrics \n",
    "            with torch.no_grad():\n",
    "                decode_acc = get_decoder_accuracy(full_vid_embedder, full_neu_embedder, test_loader_single, modality=config[\"modality\"], device=device)\n",
    "                test_loss = 0\n",
    "                for i, (stimulus, targets) in enumerate(test_loader):\n",
    "                    vids = stimulus.to(device)\n",
    "                    neus = targets.to(device)\n",
    "                    vid_embed = full_vid_embedder(vids)\n",
    "                    neu_embed = full_neu_embedder(neus)\n",
    "                    loss = triplet_loss(vid_embed, neu_embed, alpha) + triplet_loss(neu_embed, vid_embed, alpha)\n",
    "                    test_loss += loss.item()\n",
    "                    \n",
    "            if config[\"wandb\"]:\n",
    "                wandb.log({\"decode_acc\": np.nanmean(decode_acc), \"train_loss\": epoch_loss / len(train_loader), \"test_loss\": test_loss / len(test_loader)})\n",
    "            \n",
    "            if np.nanmean(decode_acc) > sess_corr_avg:\n",
    "                sess_corr_avg = np.nanmean(decode_acc)\n",
    "                sess_corrs = decode_acc\n",
    "                \n",
    "            print('  epoch {} loss: {} decode acc: {}'.format(epochs + 1, epoch_loss / len(train_dataset), np.nanmean(decode_acc)))\n",
    "            #print(f' num. neurons : {len(decode_acc)}')\n",
    "            \n",
    "        #if config[\"save\"]:\n",
    "        #    torch.save(full_model.state_dict(), f\"{model_output_path}_{session_id}.pickle\")\n",
    "            \n",
    "        corr_avgs.append(sess_corrs)\n",
    "        \n",
    "        if config[\"wandb\"]:\n",
    "            wandb.finish()\n",
    "    \n",
    "    if config[\"wandb\"]:\n",
    "        wandb.init(\n",
    "            project=f'{config[\"modality\"]}-cs230-decode',\n",
    "            config=config,\n",
    "        )\n",
    "        for corr in corr_avgs:\n",
    "            wandb.log({\"decode_accs\": corr})\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376fdba1-b893-4528-b745-f6acfc60c177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "readout input shape: 384\n",
      "  epoch 1 loss: 10.488836178249784 decode acc: 0.05\n",
      "  epoch 2 loss: 5.966183292718581 decode acc: 0.075\n",
      "  epoch 3 loss: 5.433130971649547 decode acc: 0.075\n",
      "  epoch 4 loss: 4.960577555526922 decode acc: 0.075\n",
      "  epoch 5 loss: 4.653925652209623 decode acc: 0.075\n",
      "  epoch 6 loss: 4.289170992815936 decode acc: 0.075\n",
      "  epoch 7 loss: 3.9539900386480635 decode acc: 0.075\n",
      "  epoch 8 loss: 3.7107306680561583 decode acc: 0.05\n"
     ]
    }
   ],
   "source": [
    "full_vid_fcn = lambda train_dataset: VideoEmbedder(feat_ext_type = 'resnet3d', freeze_weights=True, use_pretrained = True, modality=config[\"modality\"], layer=config[\"layer\"], stim_shape=config[\"stim_shape\"], train_dataset=train_dataset, use_pool = config['use_pool'], pool_size = config['pool_size'], pool_stride = config[\"pool_stride\"], device=device)\n",
    "full_neu_fcn = lambda num_neurons: NeuralEmbedder(num_neurons, device=device)\n",
    "\n",
    "train_model(full_vid_fcn, full_neu_fcn, \"frozen pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6968aa85-a6e0-4394-91c4-e24b0e8c558c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
